{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers.experimental.preprocessing import StringLookup\n",
    "from tensorflow import keras\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2 as cv\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum line length is 128 characters\n"
     ]
    }
   ],
   "source": [
    "short_training_set = pd.read_csv('TrainLables.csv').drop(['Unnamed: 0'],axis=1).sort_values(by=['Image'])\n",
    "\n",
    "ll = 6*list(short_training_set['Text'])\n",
    "\n",
    "list_paths = sorted(os.listdir(\"Processed_Images\"))\n",
    "\n",
    "full_path = [\"Processed_Images/\"+i for i in list_paths]\n",
    "\n",
    "long_training_set = pd.DataFrame({'Image':full_path,\"Text\":ll})\n",
    "\n",
    "test_set = pd.read_csv('TestLabels.csv').drop(['Unnamed: 0'],axis=1).sort_values(by=['Image'])\n",
    "\n",
    "list_paths_test = sorted(os.listdir(\"Processed_Test_Images\"))\n",
    "\n",
    "full_path_test = [\"Processed_Test_Images/\"+i for i in list_paths_test]\n",
    "\n",
    "test_set['Image'] = full_path_test\n",
    "\n",
    "# identifying unique characters in the dataset\n",
    "\n",
    "characters = set(char for label in short_training_set['Text'] for char in label)\n",
    "characters = sorted(list(characters))\n",
    "\n",
    "# Maximum length of any line in the dataset\n",
    "max_length = max([len(label) for label in short_training_set['Text']])\n",
    "print('The maximum line length is {} characters'.format(max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1400 image in the short trainging set\n",
      "There are 8400 image in the long trainging set\n",
      "There are 233 image in the test set\n"
     ]
    }
   ],
   "source": [
    "print('There are '+str(len(short_training_set))+ \" image in the short trainging set\")\n",
    "print('There are '+str(len(long_training_set))+ \" image in the long trainging set\")\n",
    "print('There are '+str(len(test_set))+ \" image in the test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val(df):\n",
    "    \n",
    "    X = df[\"Image\"]\n",
    "    y = df['Text']\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    return  np.array(list(X_train)), np.array(list(X_val)), np.array(list(y_train)), np.array(list(y_val))\n",
    "\n",
    "X_train_path, X_val_Path, y_train, y_val   = train_val(long_training_set)\n",
    "\n",
    "X_test_path = list(test_set['Image'])\n",
    "y_test = list(test_set['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5880 image in the trainging set\n",
      "There are 2520 image in the validation set\n",
      "There are 233 image in the test set\n"
     ]
    }
   ],
   "source": [
    "print('There are '+str(len(X_train_path))+ \" image in the trainging set\")\n",
    "print('There are '+str(len(X_val_Path))+ \" image in the validation set\")\n",
    "print('There are '+str(len(test_set))+ \" image in the test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping characters to integers\n",
    "char_to_num = layers.StringLookup(\n",
    "    vocabulary=list(characters), mask_token=None\n",
    ")\n",
    "\n",
    "# Mapping integers back to original characters\n",
    "num_to_char = layers.StringLookup(\n",
    "    vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distortion_free_resize(image, img_size):\n",
    "    w, h = img_size\n",
    "    image = tf.image.resize(image, size=(h, w), preserve_aspect_ratio=True)\n",
    "\n",
    "    # Check tha amount of padding needed to be done.\n",
    "    pad_height = h - tf.shape(image)[0]\n",
    "    pad_width = w - tf.shape(image)[1]\n",
    "\n",
    "    # Only necessary if you want to do same amount of padding on both sides.\n",
    "    if pad_height % 2 != 0:\n",
    "        height = pad_height // 2\n",
    "        pad_height_top = height + 1\n",
    "        pad_height_bottom = height\n",
    "    else:\n",
    "        pad_height_top = pad_height_bottom = pad_height // 2\n",
    "\n",
    "    if pad_width % 2 != 0:\n",
    "        width = pad_width // 2\n",
    "        pad_width_left = width + 1\n",
    "        pad_width_right = width\n",
    "    else:\n",
    "        pad_width_left = pad_width_right = pad_width // 2\n",
    "\n",
    "    image = tf.pad(\n",
    "        image,\n",
    "        paddings=[\n",
    "            [pad_height_top, pad_height_bottom],\n",
    "            [pad_width_left, pad_width_right],\n",
    "            [0, 0],\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    image = tf.transpose(image, perm=[1, 0, 2])\n",
    "    image = tf.image.flip_left_right(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "padding_token = 99\n",
    "image_width = 2882\n",
    "image_height = 46\n",
    "\n",
    "\n",
    "def preprocess_image(image_path, img_size=(image_width, image_height)):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_png(image, channels=1) # convert to grayscale\n",
    "    image = distortion_free_resize(image, img_size) # changing the image size keeping the aspect ration through padding\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image\n",
    "\n",
    "\n",
    "def vectorize_label(label):\n",
    "    # converting sequence of character to sequence of corresponding number and keeping fixed size of the label through padding\n",
    "    label = char_to_num(tf.strings.unicode_split(label, input_encoding=\"UTF-8\"))\n",
    "    length = tf.shape(label)[0]\n",
    "    pad_amount = 128 - length\n",
    "    label = tf.pad(label, paddings=[[0, pad_amount]], constant_values=padding_token)\n",
    "    return label\n",
    "    \n",
    "\n",
    "\n",
    "def process_images_labels(image_path, label):\n",
    "    image = preprocess_image(image_path)\n",
    "    label = vectorize_label(label)\n",
    "    return {\"image\": image, \"label\": label}\n",
    "\n",
    "\n",
    "def prepare_dataset(image_paths, labels):\n",
    "    # generating dataset in batches\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels)).map(\n",
    "        process_images_labels, num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "    return dataset.batch(batch_size).cache().prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = prepare_dataset(X_train_path, y_train)\n",
    "validation_ds = prepare_dataset(X_val_Path, y_val)\n",
    "test_ds = prepare_dataset(X_test_path, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTCLayer(keras.layers.Layer):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.loss_fn = keras.backend.ctc_batch_cost\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
    "        self.add_loss(loss)\n",
    "\n",
    "        # At test time, just return the computed predictions.\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    # Inputs to the model\n",
    "    input_img = keras.Input(shape=(image_width, image_height, 1), name=\"image\")\n",
    "    labels = keras.layers.Input(name=\"label\", shape=(None,))\n",
    "\n",
    "    # First conv block.\n",
    "    x = keras.layers.Conv2D(\n",
    "        64,\n",
    "        (3, 3),\n",
    "        activation=\"relu\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "        padding=\"same\",\n",
    "        name=\"Conv1\",\n",
    "    )(input_img)\n",
    "    x = keras.layers.MaxPooling2D((2, 2), name=\"pool1\")(x)\n",
    "    x= keras.layers.BatchNormalization()(x)\n",
    "    new_shape = ((image_width // 2), (image_height // 2) * 64)\n",
    "    x = keras.layers.Reshape(target_shape=new_shape, name=\"reshape\")(x)\n",
    "    x = keras.layers.Dense(16, activation=\"relu\", name=\"dense2\")(x)\n",
    "    x= keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Bidirectional(\n",
    "        keras.layers.LSTM(128, return_sequences=True, dropout=0.35))(x)\n",
    "    x = keras.layers.Dense(\n",
    "        len(char_to_num.get_vocabulary()) + 2, activation=\"softmax\", name=\"dense3\"\n",
    "    )(x)\n",
    "    output = CTCLayer(name=\"ctc_loss\")(labels, x)\n",
    "\n",
    "    # Define the model.\n",
    "    model = keras.models.Model(\n",
    "        inputs=[input_img, labels], outputs=output, name=\"Arabic_OCR\"\n",
    "    )\n",
    "    # Optimizer.\n",
    "    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.0001,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "    opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    # Compile the model and return.\n",
    "    model.compile(optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model.\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_images = []\n",
    "validation_labels = []\n",
    "\n",
    "for batch in validation_ds:\n",
    "    validation_images.append(batch[\"image\"])\n",
    "    validation_labels.append(batch[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_edit_distance(labels, predictions):\n",
    "    # Get a single batch and convert its labels to sparse tensors.\n",
    "    saprse_labels = tf.sparse.from_dense(labels)\n",
    "\n",
    "    # Make predictions and convert them to sparse tensors.\n",
    "    input_len = np.ones(predictions.shape[0]) * predictions.shape[1]\n",
    "\n",
    "    predictions_decoded = keras.backend.ctc_decode(\n",
    "        \n",
    "        predictions, input_length=input_len, greedy=False, beam_width=100,\n",
    "    )[0][0][:, :max_length]\n",
    "    sparse_predictions =tf.sparse.from_dense(predictions_decoded)\n",
    "    \n",
    "    # Compute individual edit distances and average them out.\n",
    "    edit_distances = tf.edit_distance(\n",
    "        sparse_predictions, saprse_labels, normalize=False\n",
    "    )\n",
    "    return tf.reduce_mean(edit_distances)\n",
    "\n",
    "\n",
    "class EditDistanceCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, pred_model):\n",
    "        super().__init__()\n",
    "        self.prediction_model = pred_model\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        edit_distances = []\n",
    "\n",
    "        for i in range(len(validation_images)):\n",
    "            labels = validation_labels[i]\n",
    "            predictions = self.prediction_model.predict(validation_images[i])\n",
    "            edit_distances.append(calculate_edit_distance(labels, predictions).numpy())\n",
    "\n",
    "        print(\n",
    "            f\"Mean edit distance for epoch {epoch + 1}: {np.mean(edit_distances):.4f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30  # To get good results this should be at least 50.\n",
    "\n",
    "model = build_model()\n",
    "prediction_model = keras.models.Model(\n",
    "    model.get_layer(name=\"image\").input, model.get_layer(name=\"dense3\").output\n",
    ")\n",
    "edit_distance_callback = EditDistanceCallback(prediction_model)\n",
    "\n",
    "stopping=tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=3,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=False,\n",
    ")\n",
    "\n",
    "# Train the model.\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=validation_ds,\n",
    "    epochs=epochs,\n",
    "    callbacks=[edit_distance_callback],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "#add early stopping mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_batch_predictions(pred):\n",
    "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
    "    # Use greedy search. For complex tasks, you can use beam search.\n",
    "    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0][\n",
    "        :, :max_length\n",
    "    ]\n",
    "    # Iterate over the results and get back the text.\n",
    "    output_text = []\n",
    "    for res in results:\n",
    "        res = tf.gather(res, tf.where(tf.math.not_equal(res, -1)))\n",
    "        res = tf.strings.reduce_join(num_to_char(res)).numpy().decode(\"utf-8\")\n",
    "        output_text.append(res)\n",
    "    print(output_text)\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Let's check results on some test samples.\n",
    "for batch in test_ds.take(1):\n",
    "    batch_images = batch[\"image\"]\n",
    "    _, ax = plt.subplots(4, 4, figsize=(20, 8))\n",
    "\n",
    "    preds = prediction_model.predict(batch_images)\n",
    "    pred_texts = decode_batch_predictions(preds)\n",
    "\n",
    "    for i in range(16):\n",
    "        img = batch_images[i]\n",
    "        img = tf.image.flip_left_right(img)\n",
    "        img = tf.transpose(img, perm=[1, 0, 2])\n",
    "        img = (img * 255.0).numpy().clip(0, 255).astype(np.uint8)\n",
    "        img = img[:, :, 0]\n",
    "\n",
    "        title = f\"Prediction: {pred_texts[i]}\"\n",
    "        print(pred_texts[i]=='')\n",
    "        ax[i // 4, i % 4].imshow(img, cmap=\"gray\")\n",
    "        ax[i // 4, i % 4].set_title(title)\n",
    "        ax[i // 4, i % 4].axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['val_loss'][2:len(history.history['val_loss'])-1])\n",
    "plt.plot(history.history['loss'][2:len(history.history['loss'])-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['val_loss'][1:len(history.history['val_loss'])-1])\n",
    "plt.plot(history.history['loss'][1:len(history.history['loss'])-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['val_loss'])\n",
    "plt.plot(history.history['loss'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
